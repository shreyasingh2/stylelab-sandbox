{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7/uv0I34aD/8DHd070Vx7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyasingh2/stylelab-sandbox/blob/main/StyleLabV0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python numpy matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqzEwD1UbEX6",
        "outputId": "85b3d863-a4f9-421d-d281-2666d525ca80"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "\n",
        "def load_image(path):\n",
        "    \"\"\"\n",
        "    Load an image from disk and return (BGR, RGB) versions.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not load image at {path}\")\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img, img_rgb\n",
        "\n",
        "\n",
        "def draw_landmarks(image_rgb, landmarks):\n",
        "    \"\"\"\n",
        "    Draw pose landmarks as small dots on the image and display it.\n",
        "    \"\"\"\n",
        "    img = image_rgb.copy()\n",
        "    h, w, _ = img.shape\n",
        "    for lm in landmarks:\n",
        "        x = int(lm.x * w)\n",
        "        y = int(lm.y * h)\n",
        "        cv2.circle(img, (x, y), 3, (0, 255, 0), -1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def euclidean_distance(a, b):\n",
        "    \"\"\"\n",
        "    Euclidean distance between two MediaPipe landmarks in normalized coordinates.\n",
        "    \"\"\"\n",
        "    return math.sqrt((a.x - b.x)**2 + (a.y - b.y)**2 + (a.z - b.z)**2)\n",
        "\n",
        "\n",
        "def joint_angle(a, b, c):\n",
        "    \"\"\"\n",
        "    Angle at point b formed by points a-b-c in degrees.\n",
        "    Returns None if something is degenerate.\n",
        "    \"\"\"\n",
        "    ba = np.array([a.x - b.x, a.y - b.y, a.z - b.z])\n",
        "    bc = np.array([c.x - b.x, c.y - b.y, c.z - b.z])\n",
        "\n",
        "    norm_ba = np.linalg.norm(ba)\n",
        "    norm_bc = np.linalg.norm(bc)\n",
        "    if norm_ba == 0 or norm_bc == 0:\n",
        "        return None\n",
        "\n",
        "    cos_angle = np.dot(ba, bc) / (norm_ba * norm_bc)\n",
        "    cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
        "    angle = math.degrees(math.acos(cos_angle))\n",
        "    return angle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhUkbma5cE7r",
        "outputId": "62cd6e64-6abd-4d3c-b9cd-af26a8e90b97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jaxlib/plugin_support.py:71: RuntimeWarning: JAX plugin jax_cuda12_plugin version 0.7.2 is installed, but it is not compatible with the installed jaxlib version 0.7.1, so it will not be used.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üì§ Upload an image and set IMAGE_PATH automatically\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"Upload a full-body image (PNG/JPG).\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    fname = list(uploaded.keys())[0]\n",
        "    IMAGE_PATH = os.path.join(\"/content\", fname)\n",
        "    print(f\"\\n‚úÖ Image uploaded successfully!\")\n",
        "    print(f\"üìç IMAGE_PATH set to: {IMAGE_PATH}\")\n",
        "\n",
        "    # Load & show basic preview (optional)\n",
        "    img_bgr, img_rgb = load_image(IMAGE_PATH)\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis(\"off\")\n",
        "else:\n",
        "    print(\"No file uploaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "KEDA4fMhcXLp",
        "outputId": "0285044c-eb24-4aad-caef-4d950f5570d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload a full-body image (PNG/JPG).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d0c817de-08a8-4325-bd04-b6c4389a998e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d0c817de-08a8-4325-bd04-b6c4389a998e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ‚ú® Feature Extraction\n",
        "\n",
        " ## From the pose landmarks we compute a **small, powerful feature set**:\n",
        "\n",
        " ## - `height` ‚Äì nose to ankles (normalized distance)\n",
        " ## - `leg_torso_ratio` ‚Äì leg length vs torso length\n",
        " ## - `shoulder_width` & `hip_width`\n",
        " ## - `shoulder_hip_ratio` ‚Äì Yang vs Yin in width\n",
        " ## - `body_aspect_ratio` ‚Äì tall vs compact in the frame\n",
        " ## - `joint_softness` ‚Äì rough proxy for straight vs curved joints\n"
      ],
      "metadata": {
        "id": "rvBHYOi3eA8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_body_features(landmarks):\n",
        "    # MediaPipe Pose indices\n",
        "    NOSE = 0\n",
        "    LEFT_SHOULDER = 11\n",
        "    RIGHT_SHOULDER = 12\n",
        "    LEFT_HIP = 23\n",
        "    RIGHT_HIP = 24\n",
        "    LEFT_KNEE = 25\n",
        "    RIGHT_KNEE = 26\n",
        "    LEFT_ANKLE = 27\n",
        "    RIGHT_ANKLE = 28\n",
        "    LEFT_ELBOW = 13\n",
        "    RIGHT_ELBOW = 14\n",
        "    LEFT_WRIST = 15\n",
        "    RIGHT_WRIST = 16\n",
        "\n",
        "    l = landmarks  # shorthand\n",
        "\n",
        "    # Midpoints: hips, shoulders, ankles\n",
        "    mid_hips = landmark_pb2.NormalizedLandmark()\n",
        "    mid_hips.x = (l[LEFT_HIP].x + l[RIGHT_HIP].x) / 2\n",
        "    mid_hips.y = (l[LEFT_HIP].y + l[RIGHT_HIP].y) / 2\n",
        "    mid_hips.z = (l[LEFT_HIP].z + l[RIGHT_HIP].z) / 2\n",
        "\n",
        "    mid_shoulders = landmark_pb2.NormalizedLandmark()\n",
        "    mid_shoulders.x = (l[LEFT_SHOULDER].x + l[RIGHT_SHOULDER].x) / 2\n",
        "    mid_shoulders.y = (l[LEFT_SHOULDER].y + l[RIGHT_SHOULDER].y) / 2\n",
        "    mid_shoulders.z = (l[LEFT_SHOULDER].z + l[RIGHT_SHOULDER].z) / 2\n",
        "\n",
        "    mid_ankles = landmark_pb2.NormalizedLandmark()\n",
        "    mid_ankles.x = (l[LEFT_ANKLE].x + l[RIGHT_ANKLE].x) / 2\n",
        "    mid_ankles.y = (l[LEFT_ANKLE].y + l[RIGHT_ANKLE].y) / 2\n",
        "    mid_ankles.z = (l[LEFT_ANKLE].z + l[RIGHT_ANKLE].z) / 2\n",
        "\n",
        "    # --- CORE VERTICAL MEASUREMENTS ---\n",
        "\n",
        "    # Total \"height\" (nose to ankles)\n",
        "    height = euclidean_distance(mid_ankles, l[NOSE])\n",
        "\n",
        "    # Leg length: hips ‚Üí ankles (lower body)\n",
        "    leg_length = euclidean_distance(mid_hips, mid_ankles)\n",
        "\n",
        "    # Torso length: shoulders ‚Üí hips (upper body / torso)\n",
        "    torso_length = euclidean_distance(mid_shoulders, mid_hips)\n",
        "\n",
        "    # Vertical ratio of legs vs torso (simple vertical body ratio)\n",
        "    if torso_length == 0:\n",
        "        leg_torso_ratio = None\n",
        "    else:\n",
        "        torso_leg_ratio = torso_length / leg_length  # >1 = long legs (Yang), <1 = longer torso (Yin)\n",
        "\n",
        "    if height != 0:\n",
        "        leg_height_ratio = leg_length / height       # % of height that is leg\n",
        "        torso_height_ratio = torso_length / height   # % of height that is torso\n",
        "    else:\n",
        "        leg_height_ratio = None\n",
        "        torso_height_ratio = None\n",
        "\n",
        "    # --- WIDTH MEASUREMENTS ---\n",
        "\n",
        "    shoulder_width = euclidean_distance(l[LEFT_SHOULDER], l[RIGHT_SHOULDER])\n",
        "    hip_width = euclidean_distance(l[LEFT_HIP], l[RIGHT_HIP])\n",
        "    shoulder_hip_ratio = None if hip_width == 0 else shoulder_width / hip_width\n",
        "\n",
        "    # --- OVERALL BODY ASPECT (VERTICAL LINE) ---\n",
        "\n",
        "    xs = [lm.x for lm in l]\n",
        "    ys = [lm.y for lm in l]\n",
        "    vertical_range = max(ys) - min(ys)\n",
        "    horizontal_range = max(xs) - min(xs)\n",
        "    body_aspect_ratio = None if horizontal_range == 0 else vertical_range / horizontal_range\n",
        "\n",
        "    # --- JOINT SOFTNESS (ELBOW + KNEE ANGLES) ---\n",
        "\n",
        "    left_elbow_angle = joint_angle(l[LEFT_SHOULDER], l[LEFT_ELBOW], l[LEFT_WRIST])\n",
        "    right_elbow_angle = joint_angle(l[RIGHT_SHOULDER], l[RIGHT_ELBOW], l[RIGHT_WRIST])\n",
        "    left_knee_angle = joint_angle(l[LEFT_HIP], l[LEFT_KNEE], l[LEFT_ANKLE])\n",
        "    right_knee_angle = joint_angle(l[RIGHT_HIP], l[RIGHT_KNEE], l[RIGHT_ANKLE])\n",
        "\n",
        "    angles = [a for a in [left_elbow_angle, right_elbow_angle,\n",
        "                          left_knee_angle, right_knee_angle] if a is not None]\n",
        "\n",
        "    if angles:\n",
        "        avg_angle = sum(angles) / len(angles)\n",
        "        # Distance from 180¬∞ (perfectly straight) ‚Äì rough \"softness\" proxy\n",
        "        joint_softness = abs(180 - avg_angle)\n",
        "    else:\n",
        "        joint_softness = None\n",
        "\n",
        "    features = {\n",
        "        # vertical proportions\n",
        "        \"height\": height,\n",
        "        \"leg_length\": leg_length,\n",
        "        \"torso_length\": torso_length,\n",
        "        \"leg_torso_ratio\": leg_torso_ratio,\n",
        "        \"leg_height_ratio\": leg_height_ratio,\n",
        "        \"torso_height_ratio\": torso_height_ratio,\n",
        "\n",
        "        # width / balance\n",
        "        \"shoulder_width\": shoulder_width,\n",
        "        \"hip_width\": hip_width,\n",
        "        \"shoulder_hip_ratio\": shoulder_hip_ratio,\n",
        "\n",
        "        # vertical line & sharpness\n",
        "        \"body_aspect_ratio\": body_aspect_ratio,\n",
        "        \"joint_softness\": joint_softness,\n",
        "    }\n",
        "    return features\n",
        "\n"
      ],
      "metadata": {
        "id": "WUX1QPCAeH3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## üßÆ Rule-Based Kibbe \"Lane\" Classifier (MVP)\n",
        "\n",
        "## This is a **very simple, adjustable ruleset**:\n",
        "\n",
        "## - Computes **YANG vs YIN** score from:\n",
        "  ## - vertical line (aspect)\n",
        "  ## - leg:torso\n",
        "  ## - shoulder vs hip dominance\n",
        "  ## - joint softness (optional, rough)\n",
        "\n",
        "## - Then maps patterns to **broad Kibbe neighborhoods**:\n",
        "  ## - Dramatic spectrum / Soft Dramatic\n",
        "  ## - Flamboyant Natural / Soft Natural\n",
        "  ## - Romantic / Theatrical Romantic\n",
        "  ## - Gamine / Soft Gamine\n",
        "  ## - Classic-ish / balanced\n"
      ],
      "metadata": {
        "id": "I8MoC18web_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_kibbe(features):\n",
        "    leg_torso = features[\"leg_torso_ratio\"]\n",
        "    sh_hip = features[\"shoulder_hip_ratio\"]\n",
        "    aspect = features[\"body_aspect_ratio\"]\n",
        "    shoulder_w = features[\"shoulder_width\"]\n",
        "    hip_w = features[\"hip_width\"]\n",
        "    joint_softness = features[\"joint_softness\"]\n",
        "\n",
        "    yang = 0\n",
        "    yin = 0\n",
        "\n",
        "    # --- Vertical line (aspect ratio) ---\n",
        "    if aspect is not None:\n",
        "        if aspect > 1.6:\n",
        "            yang += 1\n",
        "        if aspect > 2.0:\n",
        "            yang += 1\n",
        "        if aspect < 1.4:\n",
        "            yin += 1\n",
        "\n",
        "    # --- Leg vs torso ---\n",
        "    if leg_torso is not None:\n",
        "        if leg_torso > 1.1:\n",
        "            yang += 1\n",
        "        elif leg_torso < 0.95:\n",
        "            yin += 1\n",
        "\n",
        "    # --- Shoulder vs hip ratio ---\n",
        "    if sh_hip is not None:\n",
        "        if sh_hip > 1.1:\n",
        "            yang += 1\n",
        "        elif sh_hip < 0.95:\n",
        "            yin += 1\n",
        "\n",
        "    # --- Width dominance ---\n",
        "    if shoulder_w is not None and hip_w is not None:\n",
        "        if shoulder_w > hip_w * 1.05:\n",
        "            yang += 1\n",
        "        elif hip_w > shoulder_w * 1.05:\n",
        "            yin += 1\n",
        "\n",
        "    # --- Softness analysis: from joint_softness & hips ---\n",
        "    softness_level = \"unknown\"\n",
        "    softness_desc = \"\"\n",
        "    softness_comment = \"N/A\"\n",
        "\n",
        "    if joint_softness is not None:\n",
        "        # joint_softness ‚âà 0‚Äì90 (0 = very straight/taut, higher = more bent/soft)\n",
        "        if joint_softness < 8:\n",
        "            softness_level = \"sharp / taut\"\n",
        "            softness_comment = \"Lines read relatively straight and tight.\"\n",
        "        elif joint_softness < 20:\n",
        "            softness_level = \"moderately soft\"\n",
        "            softness_comment = \"There is some softness/relaxation in the limbs.\"\n",
        "        else:\n",
        "            softness_level = \"very soft\"\n",
        "            softness_comment = \"Limbs read quite soft/relaxed, less taut overall.\"\n",
        "    else:\n",
        "        softness_comment = \"Not enough joint data to estimate softness.\"\n",
        "\n",
        "    softness_desc = softness_comment\n",
        "\n",
        "    # Flesh softness hint via hips vs shoulders\n",
        "    if hip_w is not None and shoulder_w is not None:\n",
        "        if hip_w > shoulder_w * 1.05:\n",
        "            softness_desc += \" The lower body reads a bit fuller/curvier.\"\n",
        "        elif shoulder_w > hip_w * 1.05:\n",
        "            softness_desc += \" The upper body reads straighter/shoulder-dominant.\"\n",
        "\n",
        "    # Softness also contributes one Yin/Yang vote\n",
        "    if joint_softness is not None:\n",
        "        if joint_softness > 12:\n",
        "            yin += 1\n",
        "        elif joint_softness < 6:\n",
        "            yang += 1\n",
        "\n",
        "    delta = yang - yin\n",
        "    kibbe_guess = \"Classic / Gamine mix\"\n",
        "    explanation = []\n",
        "\n",
        "    # --- Kibbe lane mapping ---\n",
        "    if delta >= 3:\n",
        "        if hip_w is not None and hip_w >= shoulder_w * 0.95:\n",
        "            kibbe_guess = \"Soft Dramatic spectrum\"\n",
        "            explanation.append(\"Strong Yang with some Yin softness in hips ‚Üí Soft Dramatic lane.\")\n",
        "        else:\n",
        "            kibbe_guess = \"Dramatic spectrum\"\n",
        "            explanation.append(\"Strong Yang vertical & shoulders, straighter hips ‚Üí Dramatic lane.\")\n",
        "    elif 1 <= delta < 3:\n",
        "        if shoulder_w is not None and (features[\"height\"] or 1e-6) != 0 and shoulder_w / (features[\"height\"] + 1e-6) > 0.23:\n",
        "            kibbe_guess = \"Flamboyant Natural spectrum\"\n",
        "            explanation.append(\"Broad, slightly blunt frame with moderate Yang ‚Üí Flamboyant Natural lane.\")\n",
        "        else:\n",
        "            kibbe_guess = \"Soft Natural / Classic mix\"\n",
        "            explanation.append(\"Moderate Yang with some softness ‚Üí Soft Natural / Classic mix.\")\n",
        "    elif delta <= -3:\n",
        "        kibbe_guess = \"Romantic spectrum\"\n",
        "        explanation.append(\"Strong Yin dominance ‚Üí Romantic / Theatrical Romantic lane.\")\n",
        "    elif -3 < delta <= -1:\n",
        "        kibbe_guess = \"Soft Gamine / Romantic mix\"\n",
        "        explanation.append(\"Some Yin dominance with compactness or softness ‚Üí Soft Gamine / Romantic mix.\")\n",
        "    else:\n",
        "        kibbe_guess = \"Classic / Gamine mix\"\n",
        "        explanation.append(\"Yin and Yang relatively balanced ‚Üí Classic / some Gamine influence.\")\n",
        "\n",
        "        # --- Build summary text ---\n",
        "    explanation.insert(0, f\"Kibbe family: {kibbe_guess}\")\n",
        "    explanation.insert(1, f\"Yang vs Yin: {yang} vs {yin} (Œî = {delta})\")\n",
        "    explanation.append(f\"Softness level: {softness_level}\")\n",
        "\n",
        "    torso_leg = features.get(\"torso_leg_ratio\")\n",
        "    sh_hip = features.get(\"shoulder_hip_ratio\")\n",
        "    aspect = features.get(\"body_aspect_ratio\")\n",
        "    joint_softness = features.get(\"joint_softness\")\n",
        "\n",
        "    if torso_leg is not None:\n",
        "      explanation.append(f\"Torso:Leg ratio ‚âà {torso_leg:.2f}\")\n",
        "    if sh_hip is not None:\n",
        "      explanation.append(f\"Shoulder:Hip ratio ‚âà {sh_hip:.2f}\")\n",
        "    if aspect is not None:\n",
        "      explanation.append(f\"Body aspect (height:width) ‚âà {aspect:.2f}\")\n",
        "    if joint_softness is not None:\n",
        "      explanation.append(f\"Joint softness proxy ‚âà {joint_softness:.1f}\")\n",
        "\n",
        "    explanation.append(softness_desc)\n",
        "\n",
        "    return {\n",
        "        \"primary_type\": kibbe_guess,\n",
        "        \"yang_score\": yang,\n",
        "        \"yin_score\": yin,\n",
        "        \"score_delta\": delta,\n",
        "        \"softness_level\": softness_level,\n",
        "        \"softness_description\": softness_desc,\n",
        "        \"score_summary\": \"\\n\".join(explanation),\n",
        "        \"features\": features,\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "vfS-r3IKet45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kibbe_from_image(path, show_landmarks=True, verbose=False):\n",
        "    \"\"\"\n",
        "    Full pipeline:\n",
        "    - Load image\n",
        "    - Extract pose landmarks\n",
        "    - Compute body features\n",
        "    - Classify Kibbe lane\n",
        "    \"\"\"\n",
        "    bgr, rgb = load_image(path)\n",
        "    lms = get_pose_landmarks(rgb)\n",
        "    if lms is None:\n",
        "        print(\"No pose detected. Try a clearer full-body, standing image.\")\n",
        "        return None\n",
        "\n",
        "    feats = compute_body_features(lms)\n",
        "    res = classify_kibbe(feats)\n",
        "\n",
        "    # üü£ Print the full summary from the classifier\n",
        "    print(\"‚ú® Kibbe Analysis Summary\")\n",
        "    print(\"------------------------\")\n",
        "    print(res[\"score_summary\"])\n",
        "\n",
        "    # Optional: dump raw features if you want to debug numbers\n",
        "    if verbose:\n",
        "        print(\"\\nüß™ Raw feature values:\")\n",
        "        for k, v in feats.items():\n",
        "            print(f\"{k}: {v}\")\n",
        "\n",
        "    if show_landmarks:\n",
        "        draw_landmarks(rgb, lms)\n",
        "\n",
        "    return res, lms, rgb\n",
        "\n"
      ],
      "metadata": {
        "id": "J2sebiLme5gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pose_landmarks(image_rgb):\n",
        "    \"\"\"\n",
        "    Run MediaPipe Pose on an RGB image and return the list of 33 pose landmarks,\n",
        "    or None if no pose is detected.\n",
        "    \"\"\"\n",
        "    with mp_pose.Pose(static_image_mode=True, model_complexity=1) as pose:\n",
        "        results = pose.process(image_rgb)\n",
        "        if not results.pose_landmarks:\n",
        "            return None\n",
        "        return results.pose_landmarks.landmark\n"
      ],
      "metadata": {
        "id": "WTUVlV2nfm5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"Upload a full-body image (standing, head-to-feet visible):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fname in uploaded.keys():\n",
        "    IMAGE_PATH = os.path.join(\"/content\", fname)\n",
        "    print(\"Using image:\", IMAGE_PATH)\n",
        "    res, lms, rgb = kibbe_from_image(IMAGE_PATH, show_landmarks=True)\n"
      ],
      "metadata": {
        "id": "dW-fWs_2fBr9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}